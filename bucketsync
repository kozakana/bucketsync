#!/usr/bin/env ruby

require 'optparse'

# ref:
# http://s3tools.org/usage

config_filename = ".tmp_s3cfg"
ignore_filename = ".tmp_s3ignore"

dry_run_help = [
  "Only show what should be uploaded or downloaded but",
  "don't actually do it. May still perform S3 requests to",
  "get bucket listings and other information though (only",
  "or file transfer commands)"
]

option={}
OptionParser.new do |opt|
  opt.on('-e', '--env', "input access key, secret key, syncdir and bucket name from '.env' file") {|v| option[:env] = v}
  opt.on('--dry-run', *dry_run_help) {|v| option[:dry_run] = v}
  opt.on('--no-ignore', 'all files are targeted for upload') {|v| option[:no_ignore] = v}
  opt.on('--ignore=VALUE', 'set your ignore file') {|v| option[:ignore] = v}
  
  opt.permute!(ARGV)
end

class Object
  def try(method)
    if nil?
      self
    else
      public_send(method)
    end
  end
end

def read_env env_file
  elements = {}
  begin
    File.open(env_file) do |file|
      file.each_line do |line|
        rows = line.split('=')
        elem = rows.first.try(:strip)
        value = rows.last.try(:strip)
        next unless value
        elements[elem] = value.gsub('"', '').gsub('\'', '')
      end
    end
  rescue => e
    p e
  end

  elements
end

access_key, secret_key, upload_dir, bucket_name = nil
if option[:env]
  if ARGV.length > 2
    puts "too many arguments."
    exit
  end
  env = read_env('.env')
  access_key  = env['S3_ACCESS_KEY']
  secret_key  = env['S3_SECRET_KEY']
  upload_dir  = env['DEPLOY_DIR'] || ARGV[0]
  bucket_name = env['S3_BUCKET_NAME'] || ARGV[1]
else
  if ARGV.length < 4
    puts "too few arguments."
    exit
  end
  access_key  = ARGV[0]
  secret_key  = ARGV[1]
  upload_dir  = ARGV[2]
  bucket_name = ARGV[3]
end

configfile = <<"EOS"
[default]
access_key = #{access_key}
bucket_location = ap-northeast-1
cloudfront_host = cloudfront.amazonaws.com
cloudfront_resource = /2010-07-15/distribution
default_mime_type = binary/octet-stream
delete_removed = False
dry_run = False
encoding = UTF-8
encrypt = False
follow_symlinks = False
force = False
get_continue = False
gpg_command = None
gpg_decrypt = %(gpg_command)s -d --verbose --no-use-agent --batch --yes --passphrase-fd %(passphrase_fd)s -o %(output_file)s %(input_file)s
gpg_encrypt = %(gpg_command)s -c --verbose --no-use-agent --batch --yes --passphrase-fd %(passphrase_fd)s -o %(output_file)s %(input_file)s
gpg_passphrase = 
guess_mime_type = True
host_base = s3.amazonaws.com
host_bucket = %(bucket)s.s3.amazonaws.com
human_readable_sizes = False
list_md5 = False
log_target_prefix = 
preserve_attrs = True
progress_meter = True
proxy_host = 
proxy_port = 0
recursive = False
recv_chunk = 4096
reduced_redundancy = False
secret_key = #{secret_key}
send_chunk = 4096
simpledb_host = sdb.amazonaws.com
skip_existing = False
socket_timeout = 300
urlencoding_mode = normal
use_https = True
verbosity = WARNING
EOS

ignorefile = <<"EOS"
#{config_filename}
#{ignore_filename}
bucketsync
.DS_Store
.git
.git/*
.env
EOS


# create setting files
open(config_filename, "w") {|f| f.write configfile}
open(ignore_filename, "w") {|f| f.write ignorefile}

dry_run = option[:dry_run] ? '--dry-run' : ''
if option[:no_ignore] == false
 ignore = ''
else
  if option[:ignore]
    ignore = "--exclude-from #{option[:ignore]}"
  else
    ignore = "--exclude-from #{ignore_filename}"
  end
end

if bucket_name.include?('.')
  check_certificate = '--no-check-certificate'
else
  check_certificate = ''
end

command = "s3cmd sync #{dry_run} #{check_certificate} --guess-mime-type --delete-removed --add-header=Cache-Control:no-cache #{upload_dir} -P --follow-symlinks --config #{config_filename} #{ignore} s3://#{bucket_name}"

system(command)
File.unlink config_filename, ignore_filename
